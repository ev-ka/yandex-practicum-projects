## Задача

**Проект для «Викишоп» с BERT**

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75.

Инструкция по выполнению проекта

 - Загрузите и подготовьте данные.
 - Обучите разные модели.
 - Сделайте выводы.

### Цель проекта
 - построить модель классификации комментариев на позитивные и негативные,
 - для оценки качества использовать метрику F1
 - значение метрики F1 не должно быть меньше 0.75

## Данные

Данные находятся в файле `toxic_comments.csv`. Столбец `text` в нём содержит текст комментария, а toxic — целевой признак.

## Используемые библиотеки
*pandas*, *sklearn*, *matplotlib*, *seaborn*, *optuna*, *xgboost*, *catboost*, *nltk*, *spacy*, *transformers*, *wordcloud*, *tqdm*, *torch*

## Результаты
В ходе выполнения проекта исходные текстовые данные были преобразованы в TF-IDF embeddings и BERT embeddings. На основе этих данных обучены и исследованы неколько модлелей. Детальные результаты исследования приведены в тетрадке `wikishop_project.ipynb`. По итогам проекта получена модель, значение метрики качества F1 которой не меньше 0.75.